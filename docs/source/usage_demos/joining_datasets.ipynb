{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates loading individual datasets and joining them into combined datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ecogdata.datasource import MappedSource, PlainArraySource\n",
    "from ecogdata.devices.data_util import load_experiment_auto, join_datasets, load_datasets\n",
    "\n",
    "from ecogdata.expconfig import available_sessions, session_info, session_conf\n",
    "\n",
    "from ecogdata.devices.load.file2data import FileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an arbitrary set of tone-stimulated recordings from an awake recording session\n",
    "session = available_sessions('16017')[1]\n",
    "info = session_conf(session)\n",
    "\n",
    "recordings = []\n",
    "for key in info:\n",
    "    if 'tones_tab' not in info[key]:\n",
    "        continue\n",
    "    if info[key].tones_tab.endswith('txt'):\n",
    "        recordings.append(key)\n",
    "print(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment recording loading from session config \"database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(load_experiment_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_experiment_auto` method delegates loading to specific data-wrangling code for each acquisition system. See modules in `ecogdata.devices.load...`. There are different arguments for each system. Most loaders implement a form of the `ecogdata.devices.load.file2data.FileLoader` class (see doc below). *This is an ongoing migration.*\n",
    "\n",
    "Some load arguments are specified in `info.session`, and some may be over-ridden in the recording subsections.\n",
    "\n",
    "Final priority is given to load arguments specified at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mapped='r+' to ensure read-write access -- this will create a temp file.\n",
    "dataset = load_experiment_auto(session, recordings[0], mapped='r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has mapped sources (primary is `data`). The other timeseries (`adc` and `aux`) are actually just references to the `aligned_arrays` from the primary `MappedSource`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "print()\n",
    "aligned_arrays = [k + ': ' + str(getattr(dataset.data, k)) for k in dataset.data.aligned_arrays]\n",
    "print('Aligned arrays tracked by dataset.data:')\n",
    "print('\\n'.join(aligned_arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple datasource joining\n",
    "\n",
    "Data sources (either mapped or loaded) can be joined with `source.join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = load_experiment_auto(session, recordings[1], mapped='r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joined set is the simple concatenation of the two sets (with all the aligned arrays appended as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_dataset = dataset.data.join(dataset2.data)\n",
    "print(dataset.data.shape, '+', dataset2.data.shape, '=', joined_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the memory mapping for the two single recording sources is a plain `HDF5Buffer` that mediates smart read/write interfacing with the mapped data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.data.data_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buffer for the joined dataset is a `BufferBinder`. This object does not create a new mapped file, but binds multiple source files together into a single source. This is done by managing hand-offs when indexing between sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(joined_dataset.data_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(200), dataset.data[0, -200:], label='last segment of source 1')\n",
    "plt.plot(np.arange(200, 400), dataset2.data[0, :200], label='first segment of source 2')\n",
    "t1 = dataset.data.shape[1]\n",
    "# BufferBinder can slice thru the two sets using hand-off\n",
    "plt.plot(np.arange(400), joined_dataset[0, t1 - 200:t1 + 200] + 50, label='spanning segment joined set')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining recording datasets\n",
    "The mapped datasources are easily joined. But metadata like channel maps, sampling rate, and stimulation event timestamps need to be joined as well. Use `ecogdata.devices.data_util.join_datasets` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(join_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join_datasets() only combines channels that are unmasked for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply channel masking to demonstrate map intersecting\n",
    "mask = dataset.data.binary_channel_mask\n",
    "mask[:10] = False\n",
    "dataset.data.set_channel_mask(mask)\n",
    "dataset.chan_map = dataset.chan_map.subset(mask)\n",
    "joined_set = join_datasets([dataset, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the lengths of relevant arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [joined_set[attr].shape for attr in ['data', 'adc', 'aux', 'pos_edge']]\n",
    "shapes.append(len(joined_set.exp))\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set.chan_map.image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use load_datasets to load multiple recordings at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_datasets(session, recordings[:4], load_kwargs=dict(mapped='r+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_dataset)\n",
    "print()\n",
    "print('----- Other info -----')\n",
    "print('Dataset name (joined names):', full_dataset.name)\n",
    "print('Data shape:', full_dataset.data.shape)\n",
    "print('Number of tones:', len(full_dataset.exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other join options\n",
    "\n",
    "Load the joined set to memory (from mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_datasets potentially modifies input -- reset the channel mask on second data source \n",
    "dataset2.data.set_channel_mask(None)\n",
    "joined_set = join_datasets([dataset, dataset2], source_type='loaded', popdata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [joined_set[attr].shape for attr in ['data', 'adc', 'aux', 'pos_edge']]\n",
    "shapes.append(len(joined_set.exp))\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join from a mixture of loaded and mapped sources and put the result into a `MappedSource`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = load_experiment_auto(session, recordings[1], mapped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_set = join_datasets([dataset, dataset2], source_type='mapped')\n",
    "joined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [joined_set[attr].shape for attr in ['data', 'adc', 'aux', 'pos_edge']]\n",
    "shapes.append(len(joined_set.exp))\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join from a mixture of loaded and mapped sources and load the result into a `PlainArraySource`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = load_experiment_auto(session, recordings[1], mapped=False)\n",
    "joined_set = join_datasets([dataset, dataset2], source_type='loaded')\n",
    "joined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [joined_set[attr].shape for attr in ['data', 'adc', 'aux', 'pos_edge']]\n",
    "shapes.append(len(joined_set.exp))\n",
    "print(shapes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
